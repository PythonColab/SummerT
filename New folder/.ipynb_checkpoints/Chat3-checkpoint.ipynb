{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg # Large SpaCy model for English language\n",
    "import numpy as np\n",
    "import re # regular expressions\n",
    "import spacy # NLU library\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC # Support Vector Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_format = \"IN: {input}\\nOUT: {output}\\n\" + \"_\"*50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_exact = {\n",
    "    \"what would you like to eat tonight?\": \"Pasta with salmon and red pesto please!\",\n",
    "    \"what time will you be home tonight?\": \"I will be home around 6 pm.\",\n",
    "    \"default\": \"I love you too!\"\n",
    "}\n",
    "\n",
    "def respond_exact(text):\n",
    "    response = responses_exact.get(text.lower(), responses_exact['default'])\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: What would you like to eat tonight?\n",
      "OUT: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "IN: What time will you be home tonight?\n",
      "OUT: I will be home around 6 pm.\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "IN: I just found out my boss is leaving the company.\n",
      "OUT: I love you too!\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_exact(\"What would you like to eat tonight?\"))\n",
    "print(\"_\"*50)\n",
    "print(respond_exact(\"What time will you be home tonight?\"))\n",
    "print(\"_\"*50)\n",
    "print(respond_exact(\"I just found out my boss is leaving the company.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords that can help determine the intent \n",
    "intent_keywords = {\n",
    "    'dinner_preference': ['eat', 'dinner', 'food', 'cook', 'craving'],\n",
    "    'arrival_time': ['time', 'when', 'get here', 'be home']\n",
    "}\n",
    "# Create a dictionary of patterns\n",
    "patterns = {intent: re.compile('|'.join(keys)) for intent, keys in intent_keywords.items()}\n",
    "\n",
    "# Define a function to find the intent of a message\n",
    "def get_intent_re(message):\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if pattern.search(message):\n",
    "            return(intent)\n",
    "    else:\n",
    "        return('default')\n",
    "\n",
    "responses_re = {\n",
    "    \"dinner_preference\":\"Pasta with salmon and red pesto please!\",\n",
    "    \"arrival_time\": \"I will be home around 6 pm.\",\n",
    "    \"default\":\"I like you too!\"\n",
    "}\n",
    "\n",
    "def respond_re(text):\n",
    "    response = responses_re.get(get_intent_re(text))\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: what would you like to eat tonight?\n",
      "OUT: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n",
      "IN: what time will you be home tonight?\n",
      "OUT: I will be home around 6 pm.\n",
      "__________________________________________________\n",
      "IN: I just food out my boss is leaving the company.\n",
      "OUT: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_re(\"what would you like to eat tonight?\"))\n",
    "print(respond_re(\"what time will you be home tonight?\"))\n",
    "print(respond_re(\"I just food out my boss is leaving the company.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = [\n",
    "    \"What would you like to have for dinner?\",\n",
    "    \"What do you want to eat tonight?\",\n",
    "    \"I don't know what to cook tonight.\",\n",
    "    \"Do you have any cravings?\",\n",
    "    \"Can I get you something to eat?\", \n",
    "    \"What time will you be home?\",\n",
    "    \"How much longer will you be?\",\n",
    "    \"When can we expect you to get here?\",\n",
    "    \"What's taking you so long?\",\n",
    "    \"At what hour will you be here?\",\n",
    "    \"Hello\",\n",
    "    \"Hi\",\n",
    "]\n",
    "training_intents = [\n",
    "    \"dinner_preference\",\n",
    "    \"dinner_preference\",\n",
    "    \"dinner_preference\",\n",
    "    \"dinner_preference\",\n",
    "    \"dinner_preference\",\n",
    "    \"arrival_time\",\n",
    "    \"arrival_time\",\n",
    "    \"arrival_time\",\n",
    "    \"arrival_time\",\n",
    "    \"arrival_time\",\n",
    "    \"greet\",\n",
    "    \"greet\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array with zeros: X\n",
    "X_train = np.zeros((len(training_sentences), \n",
    "              nlp('sentences').vocab.vectors_length))\n",
    "\n",
    "for i, sentence in enumerate(training_sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X_train[i, :] = doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a support vector classifier\n",
    "clf = SVC(C=1, gamma=\"auto\", probability=True)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train, training_intents)\n",
    "\n",
    "#Yes, a lot can be done here to check / improve model performance! We will leave that for another day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent_ml(text):\n",
    "    doc = nlp(text)\n",
    "    return(clf.predict([doc.vector])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_ml = {\n",
    "    \"dinner_preference\":\"Pasta with salmon and red pesto please!\",\n",
    "    \"arrival_time\": \"I will be home around 6 pm.\",\n",
    "    \"greet\": \"Greetings, How can I help you \",\n",
    "    \"default\":\"I like you too!\"\n",
    "}\n",
    "\n",
    "def respond_ml(text):\n",
    "    response = responses_ml.get(get_intent_ml(text), responses_ml[\"default\"])\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: what would you like to eat tonight?\n",
      "OUT: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n",
      "IN: what time will you be home tonight?\n",
      "OUT: I will be home around 6 pm.\n",
      "__________________________________________________\n",
      "IN: l\n",
      "OUT: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_ml(\"what would you like to eat tonight?\"))\n",
    "print(respond_ml(\"what time will you be home tonight?\"))\n",
    "print(respond_ml(\"l\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this to responses dict: \"default\": \"I love you too!\"\n",
    "# in the predict function: if the model is not too sure about the intent, return the string \"default\"\n",
    "    # There is a function that gives the probabilities for each of the possible outputs\n",
    "    # If the maximum probability is low, one might say that the model is not sure about the intent\n",
    "    # Note! This idea should work, but relies on the functionality of the predict_proba function:\n",
    "    # for the SVC model, the predict_proba function does not give meaningfull results for small datasets:\n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict_proba\n",
    "\n",
    "def get_intent_ml_2(text):\n",
    "    \"\"\"\n",
    "        Returns the intent from a given text, unless the model is not sure, in which case 'default' is returned\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    max_proba = max(clf.predict_proba([doc.vector])[0])\n",
    "    if(max_proba == 0.5):\n",
    "        return('default')\n",
    "    else:\n",
    "        return(clf.predict([doc.vector])[0])\n",
    "\n",
    "def respond_ml_2(text):\n",
    "    response = responses_ml.get(get_intent_ml_2(text), responses_ml[\"default\"])\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: flowers\n",
      "OUT: Pasta with salmon and red pesto please!\n",
      "__________________________________________________\n",
      "IN: flowers\n",
      "OUT: I like you too!\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_ml(  'flowers'))\n",
    "print(respond_ml_2('flowers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_entities(text):\n",
    "    \"\"\"\n",
    "        Get all entities in a given text, in a text: label_ dictionary\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = defaultdict(list)\n",
    "    for ent in doc.ents:\n",
    "        d[ent.label_].append(ent.text)\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DATE', ['next tuesday', 'wednesday']), ('ORG', ['Bengals']), ('TIME', ['tonight'])]\n"
     ]
    }
   ],
   "source": [
    "test_ents = get_all_entities('what would you like to eat tonight?, or next tuesday or wednesday fish football Bengals')\n",
    "print(sorted(test_ents.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\n",
    "    (\"dinner_preference\", \"time and date\"): \"I want to eat pasta\",\n",
    "    (\"dinner_preference\", \"time only\"): \"I want to eat pasta\",\n",
    "    (\"dinner_preference\", \"date only\"): \"I want to eat pasta\",\n",
    "    (\"dinner_preference\", \"none\"): \"When?\",\n",
    "    (\"arrival_time\", \"time and date\"): \"I will be home at six\",\n",
    "    (\"arrival_time\", \"time only\"): \"I will be home at six\",\n",
    "    (\"arrival_time\", \"date only\"): \"I will be home at six\",\n",
    "    (\"arrival_time\", \"none\"): \"When?\",\n",
    "    (\"default\", \"none\"): \"What do you want?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_ml_3(text):\n",
    "    \"\"\"Check for specification of date and time\n",
    "        If not specified, ask for clarification\n",
    "    \"\"\"\n",
    "    intent = get_intent_ml_2(text)\n",
    "        \n",
    "    if intent != 'default':\n",
    "        entities = get_all_entities(text)\n",
    "        if 'TIME' in entities and 'DATE' in entities:\n",
    "            specification = 'time and date'\n",
    "            time = ' and '.join(entities['DATE']) + ' at ' + ' and '.join(entities['TIME'])\n",
    "        elif 'TIME' in entities:\n",
    "            specification = 'time only'\n",
    "            time = ' and '.join(entities['TIME'])\n",
    "        elif 'DATE' in entities:\n",
    "            specification = 'date only'\n",
    "            time = ' and '.join(entities['DATE'])\n",
    "        else:\n",
    "            specification = 'none'\n",
    "            time = \"\"\n",
    "    else:\n",
    "        specification = 'none'\n",
    "        time = \"\"\n",
    "    \n",
    "    response = policy.get((intent, specification)) + ' ' + time\n",
    "    return(output_format.format(input=text, output=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferences={\"monday\" :\"pancakes\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: what would you like to eat next wednesday thursday and friday?\n",
      "OUT: I want to eat pasta next wednesday and thursday and friday\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_ml_3('what would you like to eat next wednesday thursday and friday?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: what would you like to eat next monday?\n",
      "OUT: I want to eat pasta next monday\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(respond_ml_3('what would you like to eat next monday?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
